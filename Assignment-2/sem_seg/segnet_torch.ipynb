{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sn \n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "from torch.utils.data import TensorDataset \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from load_warwick import load_warwick \n",
    "\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data \n",
    "# Training data: 85 images of 128x128x3 \n",
    "# Training labels: 85 images of 128x128 \n",
    "# Testing data: 60 images of 128x128x3 \n",
    "# Testing labels: 60 images of 128x128 \n",
    "xtra, ytra, xtes, ytes = load_warwick() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting model function\n",
    "# Credits: https://discuss.pytorch.org/t/reset-model-weights/19180/4\n",
    "def reset_model(model):\n",
    "    for layer in model.children(): \n",
    "       if hasattr(layer, 'reset_parameters'): \n",
    "           layer.reset_parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorensen-Dice coefficient\n",
    "def dsc(A, B):\n",
    "  \n",
    "    a = A.bool()\n",
    "    b = B.bool()\n",
    "    \n",
    "    intersect = torch.logical_and(a,b) \n",
    "\n",
    "    dice_coeff = (2.0 * intersect.sum()) / (a.sum() + b.sum()) \n",
    "     \n",
    "    return dice_coeff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of train/test data by dividing with maximum intensity \n",
    "xtra = xtra / 255\n",
    "ytra = ytra / 255\n",
    "\n",
    "xtes = xtes / 255 \n",
    "ytes = ytes / 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some dimensions\n",
    "pixels = 128 \n",
    "ntrain = xtra.shape[0] \n",
    "ntest = xtes.shape[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Torch tensors\n",
    "xtra_torch = torch.from_numpy(xtra).permute(0, 3, 1, 2).float()\n",
    "ytra_torch = torch.from_numpy(ytra) \n",
    "xtes_torch = torch.from_numpy(xtes).permute(0, 3, 1, 2).float()\n",
    "ytes_torch = torch.from_numpy(ytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", torch.cuda.get_device_name(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loader for training data \n",
    "num_batch = 10 \n",
    "training_set = TensorDataset(xtra_torch.to(device), ytra_torch.to(device))  \n",
    "training_loader = DataLoader(training_set, shuffle = True, batch_size = num_batch) \n",
    "\n",
    "xtest = xtes_torch.to(device) \n",
    "ytest = ytes_torch.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional network\n",
    "segnet = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = (3,3), stride = 1, padding = 1), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3,3), stride = 1, padding = 1), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3,3), stride = 1, padding = 1), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3), stride = 1, padding = 1),  nn.ReLU(), \n",
    "                        nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 32, out_channels = 16, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 16, out_channels = 8, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 2, kernel_size = (1,1), stride = 1, padding = 0)) \n",
    "\n",
    "segnetbn = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = (3,3), stride = 1, padding = 1), nn.BatchNorm2d(8), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3,3), stride = 1, padding = 1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3,3), stride = 1, padding = 1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3), stride = 1, padding = 1), nn.BatchNorm2d(64), nn.ReLU(), \n",
    "                        nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 32, out_channels = 16, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 16, out_channels = 8, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 2, kernel_size = (1,1), stride = 1, padding = 0), nn.Sigmoid()) \n",
    "\n",
    "m_seg_selu = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = (3,3), stride = 1, padding = 1), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3,3), stride = 1, padding = 1), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3,3), stride = 1, padding = 1), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3,3), stride = 1, padding = 1), nn.SELU(),\n",
    "                        nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 32, out_channels = 16, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 16, out_channels = 8, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 2, kernel_size = (1,1), stride = 1, padding = 0)) \n",
    "\n",
    "m_seg_k_big = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = (5,5), stride = 1, padding = 2), nn.BatchNorm2d(8), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (5,5), stride = 1, padding = 2), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (5,5), stride = 1, padding = 2), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (5,5), stride = 1, padding = 2), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (5,5), stride = 1, padding = 2), nn.BatchNorm2d(128), nn.ReLU(), \n",
    "                        nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 32, out_channels = 16, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 16, out_channels = 8, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 2, kernel_size = (1,1), stride = 1, padding = 0)) \n",
    "\n",
    "\n",
    "m_seg_k_big_selu = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = (5,5), stride = 1, padding = 2), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (5,5), stride = 1, padding = 2), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (5,5), stride = 1, padding = 2), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (5,5), stride = 1, padding = 2), nn.SELU(), nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                        nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (5,5), stride = 1, padding = 2), nn.SELU(), \n",
    "                        nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 32, out_channels = 16, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.ConvTranspose2d(in_channels = 16, out_channels = 8, kernel_size = (4,4), stride = 2, padding = 1), \n",
    "                        nn.Conv2d(in_channels = 8, out_channels = 2, kernel_size = (1,1), stride = 1, padding = 0), nn.Sigmoid()) \n",
    "\n",
    "# Selecting model \n",
    "model = segnetbn \n",
    "\n",
    "# Resetting model when we switch architectures \n",
    "reset_model(model) \n",
    "\n",
    "# Moving model to GPU \n",
    "model.to(device) \n",
    "\n",
    "# Check dimensions through network \n",
    "# Credits: https://d2l.ai/chapter_convolutional-neural-networks/lenet.html\n",
    "check_dims = False       \n",
    "if check_dims == True: \n",
    "    X = torch.rand(size = (num_batch, 3, 128, 128)).to(device) \n",
    "    for layer in model: \n",
    "        X = layer(X) \n",
    "        print(layer.__class__.__name__, 'output shape:\\t', X.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function(s)\n",
    "bce = F.binary_cross_entropy \n",
    "bce_logits = F.binary_cross_entropy_with_logits \n",
    "\n",
    "it = 0 \n",
    "num_epochs = 300 \n",
    "l_rate = 0.001 # 0.001 works good \n",
    "\n",
    "sgd_opt = optim.SGD(model.parameters(), lr = l_rate, weight_decay = 0, momentum = 0.0) \n",
    "\n",
    "rmsp_opt = optim.RMSprop(model.parameters(), lr = l_rate, alpha = 0.99, eps = 1e-08, weight_decay = 0, momentum = 0.1, centered = False) \n",
    "\n",
    "adam_opt = optim.Adam(model.parameters(), lr = l_rate, betas = (0.9, 0.999), eps = 1e-08, weight_decay = 0.0, amsgrad = False) \n",
    "\n",
    "adad_opt = optim.Adadelta(model.parameters(), lr = 1.0, rho = 0.9, eps = 1e-06, weight_decay = 0) \n",
    " \n",
    "adag_opt = optim.Adagrad(model.parameters(), lr = 0.01, lr_decay = 0, weight_decay = 0, initial_accumulator_value = 0, eps = 1e-10) \n",
    "\n",
    "adamax_opt = optim.Adamax(model.parameters(), lr = 0.002, betas = (0.9, 0.999), eps = 1e-08, weight_decay = 0) \n",
    "\n",
    "asgd_opt = optim.ASGD(model.parameters(), lr = 0.01, lambd = 0.0001, alpha = 0.75, t0 = 1000000.0, weight_decay = 0) \n",
    "\n",
    "#sched = torch.optim.lr_scheduler.ExponentialLR(optr, gamma, last_epoch = -1, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optr = adam_opt \n",
    "dscore = [] \n",
    "bcetrain = [] \n",
    "bcetest = [] \n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    model.train() \n",
    "    for xbatch, ybatch in training_loader: \n",
    "        optr.zero_grad() \n",
    "        \n",
    "        prediction = model(xbatch) \n",
    "        pred = prediction.mean(1) # float32, ybatch float64 \n",
    "        #pred = prediction.amax(1) \n",
    "        \n",
    "        bce_l = bce_logits(pred, ybatch) \n",
    "        bcetrain.append(bce_l.item()) \n",
    "        \n",
    "        bce_l.backward() \n",
    "        optr.step() \n",
    "        #sched.step() \n",
    "        \n",
    "        model.eval() \n",
    "        with torch.no_grad(): \n",
    "            testpreds = model(xtest) \n",
    "            testpred = testpreds.mean(1) \n",
    "            #estpred = testpreds.amax(1) \n",
    "            \n",
    "            bce_test = bce_logits(testpred, ytest) \n",
    "            bcetest.append(bce_test.item()) # ytest is float64, testpred is float32\n",
    "        \n",
    "            dice_score = dsc(testpred.double(), ytest) \n",
    "            dscore.append(dice_score.item()) \n",
    "                        \n",
    "            if epoch == (num_epochs - 1): \n",
    "                te_pred = testpred \n",
    "                test_batch = ytest \n",
    "                \n",
    "                tra_pred = pred \n",
    "                train_batch = ybatch \n",
    "        \n",
    "        it += 1 \n",
    "    print(\"Epoch %s/%s\" % (epoch + 1, num_epochs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1) \n",
    "train, = plt.plot(bcetrain, 'r') \n",
    "test, = plt.plot(bcetest, 'b') \n",
    "plt.xlabel(\"Iteration\") \n",
    "plt.ylabel(\"Loss\") \n",
    "plt.title(\"Training and testing loss\") \n",
    "plt.legend([train, test], ['Train loss', 'Test loss']) \n",
    "plt.annotate(\"Final train loss: %s\" % (bcetrain[-1]) ,xycoords = 'figure fraction', xy = (0.25,0.7)) \n",
    "plt.annotate(\"Final test loss: %s\" % (bcetest[-1]), xycoords = 'figure fraction', xy = (0.25,0.75)) \n",
    "print(\"Final training loss: %s.\" % bcetrain[-1]) \n",
    "print(\"Final testing loss: %s.\" % bcetest[-1]) \n",
    "plt.savefig(\"bce_loss_plots\", dpi = 500) \n",
    "\n",
    "num = 0\n",
    "plt.figure(2) \n",
    "plt.imshow(tra_pred[num, :, :].detach().cpu(), cmap = 'jet') \n",
    "plt.title('Training prediction')\n",
    "plt.colorbar() \n",
    "plt.savefig(\"train_pred\", dpi = 500) \n",
    "plt.figure(3) \n",
    "plt.imshow(train_batch[num, :, :].detach().cpu(), cmap = 'jet') \n",
    "plt.title('Training mask')\n",
    "plt.colorbar() \n",
    "plt.savefig(\"train_mask\", dpi = 500) \n",
    "plt.figure(4) \n",
    "plt.plot(dscore, 'b') \n",
    "plt.xlabel(\"Iteration\") \n",
    "plt.ylabel(\"DSC\") \n",
    "plt.savefig(\"dice_plot\", dpi = 500) \n",
    "print(\"Final dice coefficient: %s.\" % dscore[-1]) \n",
    "\n",
    "ind = 10\n",
    "plt.figure(5) \n",
    "plt.imshow(te_pred[ind, :, :].detach().cpu(), cmap = 'jet') \n",
    "plt.title('Testing prediction')\n",
    "plt.colorbar() \n",
    "plt.savefig(\"test_pred_1\", dpi = 500) \n",
    "plt.figure(6) \n",
    "plt.imshow(test_batch[ind, :, :].detach().cpu(), cmap = 'jet') \n",
    "plt.title('Testing mask')\n",
    "plt.colorbar() \n",
    "plt.savefig(\"test_mask_1\", dpi = 500) \n",
    "\n",
    "ind = 20\n",
    "plt.figure(7) \n",
    "plt.imshow(te_pred[ind, :, :].detach().cpu(), cmap = 'jet') \n",
    "plt.title('Testing prediction')\n",
    "plt.colorbar() \n",
    "plt.savefig(\"test_pred_2\", dpi = 500) \n",
    "plt.figure(8) \n",
    "plt.imshow(test_batch[ind, :, :].detach().cpu(), cmap = 'jet') \n",
    "plt.title('Testing mask')\n",
    "plt.colorbar() \n",
    "plt.savefig(\"test_mask_2\", dpi = 500) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_cuda]",
   "language": "python",
   "name": "conda-env-torch_cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
